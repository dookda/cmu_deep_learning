{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9720b044-838b-467d-8e92-4d4ce9cf0089",
   "metadata": {},
   "source": [
    "# ws 02 03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff65191-bb41-44ed-a71f-283728908dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f1603d-c943-4b08-a2cd-a017b124a2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = './train_set'\n",
    "val_dir = './val_set'\n",
    "\n",
    "test_dir = './test_set'\n",
    "\n",
    "target_img_shape=(64, 64) \n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,  # \n",
    "        rotation_range=20,\n",
    "        height_shift_range=0.15,\n",
    "        width_shift_range=0.15, \n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "# train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_set = train_datagen.flow_from_directory(train_dir,\n",
    "                                                 target_size=target_img_shape,\n",
    "                                                 batch_size=32, \n",
    "                                                 class_mode='binary') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bb87e2-efa4-43e8-816f-356692de9e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "val_set = val_datagen.flow_from_directory(val_dir,\n",
    "                                            target_size=target_img_shape,\n",
    "                                            batch_size=32,\n",
    "                                            class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa528368-b61f-4832-8da8-4bb326967367",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training')\n",
    "ids, counts = np.unique(train_set.classes, return_counts=True)\n",
    "\n",
    "print(ids)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54301457-bc6f-4e87-9a6b-1e00c0923fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "labels  \n",
    "\n",
    "for i in ids:\n",
    "    print('{:>6} = {}' . format(labels[i], counts[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa90039-e003-4ac0-bc57-8219796fd83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Validation')\n",
    "ids, counts = np.unique(val_set.classes, return_counts=True)\n",
    "\n",
    "print(ids)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6097f2-945e-4706-9ff7-69ca77afce88",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "labels   #  labels[2] = 'elephant'\n",
    "\n",
    "for i in ids:\n",
    "    print('{:>6} = {}' . format(labels[i], counts[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec694010-b6d5-42a6-8908-8edb2bee8667",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_, train_count = np.unique(train_set.classes, return_counts=True)\n",
    "_, val_count = np.unique(val_set.classes, return_counts=True)\n",
    "\n",
    "print('Ratio Validation/Training set:', \n",
    "      val_count/(train_count+val_count) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d45942-862a-44ab-941c-bdafded348f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set[0][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f67450-27f8-408b-8770-6aedf3e158a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_set.class_indices)\n",
    "\n",
    "for image_batch, labels_batch in train_set:\n",
    "    print(image_batch.shape)\n",
    "    print(labels_batch.shape)\n",
    "    plt.imshow(image_batch[0])\n",
    "    print('class:', labels_batch[0])\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655dd6c9-2aed-4290-bebe-348bc7ae4064",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_set[0][0][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef2c77f-f1a4-43ea-8b22-3add41b89110",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(val_set[0][0][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7096be83-02dc-4c94-a8a1-3c51f03512be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(10,10))\n",
    "    for img, ax in zip(images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab9ba72-3f36-4b50-b9fc-dd8095dc71be",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_images = [train_set[0][0][0] for i in range(4)]\n",
    "plotImages(augmented_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97eb29d-d139-40b4-82a1-c481848bfb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "nplots = 8\n",
    "\n",
    "def visual_multi(images_arr):\n",
    "    fig = plt.figure(figsize=(11, 8)) \n",
    "    for j in range(nplots):\n",
    "\n",
    "        plt.subplot(3, 4, j+1)\n",
    "        plt.imshow(images_arr[j])\n",
    "\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "augmented_images = [train_set[0][0][0] for i in range(nplots)]\n",
    "visual_multi(augmented_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182a00da-c4a4-42a3-b181-9e11598390af",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab2c94d-4937-4f7b-abdf-3c4d22bdcbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_shape=(target_img_shape[0],target_img_shape[1],3)\n",
    "in_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac37d43a-1061-4db1-be77-db1a01aac3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import (Dense, Conv2D, AveragePooling2D, \n",
    "Flatten, Dropout, MaxPool2D )\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), activation='relu', input_shape=in_shape)) \n",
    "model.add(MaxPool2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPool2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3,3), activation='relu')) \n",
    "model.add(MaxPool2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))  # \n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de9b200-f015-41eb-9554-eb78f6cb8a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03a965b-cf85-443d-a97f-64a6ce6a3e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d43463d-84d7-4ebc-9728-6c5b33b043f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "history = model.fit(train_set, steps_per_epoch=len(train_set),\n",
    "                     validation_data=val_set, \n",
    "                    epochs=40, verbose=1) \n",
    "\n",
    "end = time.time()\n",
    "print(\"Time Taken: {:.2f} minutes\".format((end - start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c7fd49-b7b6-4f5e-883f-3bcb8badc938",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 3.5))\n",
    "plt.subplot(1, 2, 1)\n",
    "\n",
    "plt.title('Loss')\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'],'r', lw=3.2, label='Validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Accuracy')\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Training')\n",
    "plt.plot(history.history['val_accuracy'], 'r', lw=3.2, label='Validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f5839a-f4eb-4e08-b1ea-a6e9275ed581",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = model.evaluate(val_set, steps=len(val_set), verbose=0)\n",
    "print('score = {:.3f}' .format(acc[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890ab5af-8115-44e3-948e-7a2035146c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "target_img_shape=(64, 64)\n",
    "\n",
    "test_image = image.load_img('../dog-2.jpg', target_size=target_img_shape)  # PIL\n",
    "\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image /= 255.0\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.imshow(test_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d9f583-52ca-49eb-b199-7f2f8bee7565",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "test_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90bfdc4-5068-4534-bbe3-0b8dd782bde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(test_image)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aac844b-559c-4b37-9f48-11acc3762301",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b4b3a3-9218-4573-b031-43017b900487",
   "metadata": {},
   "outputs": [],
   "source": [
    "if result[0][0] > 0.5:\n",
    "    predict='Dog'\n",
    "else:\n",
    "    predict='Cat'\n",
    "\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4bac92-6821-43f1-bbd1-a6a2ce799910",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = 'Dog' if result[0][0] > 0.5 else 'Cat'\n",
    "cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cd03b5-b9ad-422b-93ac-936508f0c86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "def predict_dog_cat(lst):\n",
    "    y_pred = [] ; y_pred_cls = []; img_lst = []\n",
    "    for i in lst:\n",
    "        \n",
    "        img = load_img(i, target_size=target_img_shape)\n",
    "        img = img_to_array(img)\n",
    "        img /= 255.0\n",
    "      \n",
    "        \n",
    "        img_lst.append(img)\n",
    "\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "        y_pred_i = model.predict(img)\n",
    "        y_pred_cls_i = 'Dog' if y_pred_i > 0.5 else 'Cat'  # \n",
    "#         if y_pred_i[0] > 0.5:\n",
    "#             y_pred_cls_i = 'Dog'\n",
    "#         else:\n",
    "#             y_pred_cls_i = 'Cat'\n",
    "            \n",
    "        y_pred.append(y_pred_i)\n",
    "        y_pred_cls.append(y_pred_cls_i)\n",
    "\n",
    "    return img_lst, y_pred_cls, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8d2c45-adc0-4b2a-a350-7b65e0275a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "mylist = [f for f in glob.glob('./test_predict/*')]\n",
    "\n",
    "img_lst,y_pred_cls,y_pred = predict_dog_cat(mylist) \n",
    "\n",
    "mylist\n",
    "for i in mylist:\n",
    "    print(os.path.basename(i), end=' | ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b502fe-b131-4691-95be-390b5eb8e5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nplots = 10\n",
    "fig = plt.figure(figsize=(10, 5)) \n",
    "\n",
    "for i, k in enumerate(img_lst):\n",
    "\n",
    "    plt.subplot(nplots//5, 5, i+1)\n",
    "    plt.imshow(k, cmap=plt.cm.gray_r)\n",
    "    plt.title('p--> {} {}'.format(y_pred_cls[i],y_pred[i][0].round(3)))\n",
    "    \n",
    "    fname = os.path.basename(mylist[i])\n",
    "    plt.title('p--> {} {}\\n{}'.format(y_pred_cls[i],y_pred[i][0].round(3), fname))\n",
    "\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    if i >= nplots-1:  # \n",
    "        break\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

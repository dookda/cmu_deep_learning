{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f0b8682-348d-4445-b719-9f0b75abe4d1",
   "metadata": {},
   "source": [
    "# ws 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f475aa-7e3b-4a13-9e9c-57b08cfabb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten #\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003bd9c3-8dc3-43d9-a76e-915a284ce0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_img_shape = (64, 64)  \n",
    "\n",
    "train_dir = './train_set'  \n",
    "val_dir = './val_set'  # \n",
    "\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input) \n",
    "train_set = train_datagen.flow_from_directory(train_dir,\n",
    "                                                 target_size=target_img_shape,\n",
    "                                                 batch_size=32,\n",
    "                                                 class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2785bd76-1db4-40da-a5dc-2aea2d258bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "    \n",
    "val_set = val_datagen.flow_from_directory(val_dir,\n",
    "                                            target_size=target_img_shape,\n",
    "                                            batch_size=32,\n",
    "                                            class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f2d065-29b9-4214-b3cc-e1759c94d51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = train_set.next()\n",
    "print(batch[0].shape)\n",
    "print(batch[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eae7fed-d57d-420c-bb82-7ec550198eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_set.class_indices)\n",
    "for image_batch, labels_batch in train_set:\n",
    "    print(image_batch.shape)\n",
    "    print(labels_batch.shape)\n",
    "    \n",
    "    img = image_batch[0] - image_batch[0].min()\n",
    "    img /= 275.0\n",
    "    \n",
    "    print(img.min(), img.max())\n",
    "    plt.imshow(img)\n",
    "\n",
    "    print('class:', labels_batch[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe6ae0c-7ed9-4912-9706-dd8ff940ed01",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids, counts = np.unique(train_set.classes, return_counts=True)\n",
    "\n",
    "print(ids)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa10ce64-b1a0-446a-a07a-cc62928e0996",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "labels   \n",
    "\n",
    "for i in ids:\n",
    "    print('{:>6} = {}' . format(labels[i], counts[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca015b2e-68ac-47e5-a44c-fe7339c14ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = [k for k in train_set.class_indices]\n",
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9547ce08-8551-47c5-ab79-6303ffb6a95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train_labels = pd.DataFrame({'Label':label_names, 'Count':counts})\n",
    "df_train_labels.set_index('Label', inplace=True)\n",
    "df_train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140b3e9f-19b3-418a-bfe6-1cb5092440ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_labels.plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589986c9-49d1-4d1b-8001-b3073c11b244",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids, counts = np.unique(val_set.classes, return_counts=True)\n",
    "print(ids)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0bd79e-6bf5-4c6e-ab8b-3ee221ade303",
   "metadata": {},
   "source": [
    "## Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644746d8-6296-4e02-8475-cc02139950d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_shape = (target_img_shape[0], target_img_shape[1], 3)  \n",
    "in_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68b5d07-4436-466a-9409-8d11d54e404c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(include_top=False, weights='imagenet',\n",
    "                   input_shape=(64, 64, 3)) \n",
    "\n",
    "base_model.summary()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6d03d8-0427-4e15-8f88-0dedbd994637",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))  # \n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f828d2-1911-4b74-8bd9-7e530fd80e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    print('{:12} {}'.format(layer.name, layer.trainable)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5f49ba-fc69-40fd-9b15-2e18b8c50386",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    print('{:13} {}'.format(layer.name, layer.trainable)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa8d0e0-cce1-4938-b460-2cf311a937f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Trainable..\\n---\")\n",
    "for variable in model.trainable_variables:\n",
    "    print(variable.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2048669b-e388-48ea-81b5-148c023aba68",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2b2fb8-c95d-40cf-951f-e39005592f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Trainable..\\n---\")\n",
    "for variable in model.trainable_variables:\n",
    "    print(variable.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5406534-56c7-43b6-a2e0-4c63396c4069",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5833bf7-c559-46dc-81c3-7c5ec9d4deee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', verbose=1, patience=5) # \n",
    "mc = ModelCheckpoint('TL1 tr300.h5', monitor='val_accuracy', verbose=1, save_best_only=True) #\n",
    "\n",
    "start = time.time()\n",
    "history = model.fit(train_set, \n",
    "                     validation_data=val_set, \n",
    "                    epochs=20, verbose=1, callbacks=[es, mc])\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Time Taken: {:.2f} minutes\".format((end - start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e199dc6f-798d-4dad-952b-2b5ff55ac804",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 3.5))\n",
    "plt.subplot(1, 2, 1)\n",
    "\n",
    "plt.title('Loss')\n",
    "plt.plot(history.history['loss'], label='Training')\n",
    "plt.plot(history.history['val_loss'],'r', lw=3.2, label='Validation')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Accuracy')\n",
    "plt.plot(history.history['accuracy'], label='Training')\n",
    "plt.plot(history.history['val_accuracy'], 'r', lw=3.2, label='Validation')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2feef1b7-8589-4061-bbbe-434003ed4919",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = model.evaluate(val_set,  verbose=1)\n",
    "print('score = {:.3f}' .format(acc[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91061a19-3eac-4214-b979-72655a4e0f21",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b996b13-2dce-4bc2-87f4-e55d19252c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "def predict(img_fname):\n",
    "    img = load_img(img_fname, target_size=target_img_shape) \n",
    "\n",
    "    plt.imshow(img)\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = preprocess_input(img)\n",
    "    pred = model.predict(img)\n",
    "\n",
    "    pred_cls = 'Dog' if pred > 0.5 else 'Cat'  # use this of\n",
    "    print('Prediction:',pred_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fb8e07-20fb-49ca-a872-1d867700920f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict('dog010-2.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbbd1ac-a644-4d2c-8695-d5d363768a85",
   "metadata": {},
   "source": [
    "# ws 02 Fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e265c1-e511-4feb-908c-e3d475898ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Trainable..\\n---\")\n",
    "for variable in model.trainable_variables:\n",
    "    print(variable.name)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bd7434-d01f-4d4e-9a0a-11cadbbf65b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True\n",
    "\n",
    "for layer in base_model.layers[:-8]: \n",
    "    layer.trainable = False\n",
    "\n",
    "for variable in model.trainable_variables:\n",
    "    print(variable.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1651e6-c306-4dbe-8b14-d31542e7825e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b122dd3e-7160-4409-90d3-8ab29e7dcd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    # print(layer.name[:11])\n",
    "    if layer.name[:11] == 'block5_conv':\n",
    "        layer.trainable = True # \n",
    "        print(layer.name, '-> True')\n",
    "\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "        print(layer.name, '-> F') # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ebed6b-66ec-423d-a7c2-2b6dc3bc9e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Trainable..\\n---\")\n",
    "for variable in model.trainable_variables:\n",
    "    print(variable.name)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366cca9b-ac74-4726-9cac-a217f9638047",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "opt = Adam(learning_rate=1e-5)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31df4e41-d400-462e-b071-e2b6d77743dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "history = model.fit(train_set, steps_per_epoch=len(train_set),\n",
    "                     validation_data=val_set, \n",
    "                     validation_steps=len(val_set), \n",
    "                    epochs=20, verbose=1, callbacks=[es, mc])\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Time Taken: {:.2f} minutes\".format((end - start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c8c5d0-093c-4a4a-b942-c47c613d956b",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = model.evaluate(val_set, steps=len(val_set), verbose=1)\n",
    "print('score = {:.3f}' .format(acc[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c83d2c-31ea-4e2a-9283-7c4484d05899",
   "metadata": {},
   "source": [
    "# ws03 ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d516b554-e84e-49ff-ab7f-3247388c6da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input) \n",
    "train_set = train_datagen.flow_from_directory(train_dir,\n",
    "                                                 target_size=target_img_shape,\n",
    "                                                 batch_size=32, \n",
    "                                                 class_mode='binary') \n",
    "\n",
    "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input) \n",
    "    \n",
    "val_set = val_datagen.flow_from_directory(val_dir,\n",
    "                                            target_size=target_img_shape,\n",
    "                                            batch_size=32,\n",
    "                                            class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2ac05e-c80f-41d7-916b-165e80e1e18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925bd75e-e02a-41c7-81a7-90b33a9072d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet50(include_top=False, \n",
    "                    weights='imagenet',\n",
    "                   input_shape=(64, 64, 3))  \n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))  # .\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07bbf67-61b2-492a-b269-03dcd3737468",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False #  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e48801-2dc1-42ff-8d6a-3e31871d6796",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Trainable..\\n---\")\n",
    "for variable in model.trainable_variables:\n",
    "    print(variable.name)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e314a910-fd30-4f11-b86f-204fb77a9e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

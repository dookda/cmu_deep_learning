{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9d79188-100d-47fe-96c1-d635aced09e1",
   "metadata": {},
   "source": [
    "# 01 ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c56a8b-d90f-4567-bb5e-29e687914513",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8043a23b-6d21-493b-957e-a4333f019bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, _), (X_test, _) = fashion_mnist.load_data()\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdfd0f6-f518-4c5b-94c5-6854e967585f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0][:, 7:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309219b9-8022-490f-9074-799d9ea7f0a4",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad74d0c-c686-4b50-9c14-0048fee25222",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = X_train[1]\n",
    "plt.imshow(img, cmap=plt.cm.gray_r) # \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b962d45-0022-4e3d-b81f-7f537ed076e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visual_multi(i):\n",
    "\n",
    "    nplots = 16\n",
    "    fig = plt.figure(figsize=(12, 3)) #\n",
    "    for j in range(nplots):\n",
    "\n",
    "        plt.subplot(2, 8, j+1)\n",
    "        plt.imshow(X_train[i+j], cmap=plt.cm.gray_r)\n",
    "\n",
    "        plt.xticks([]); plt.yticks([])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "visual_multi(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c6d999-1bf9-445b-b81e-df0f63319c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X_train.astype('float32') / 255.0\n",
    "# X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "X_train = X_train / 255.0          #  ONCE\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caed2489-66f3-4cb0-95f2-38a239417144",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(X_train), np.max(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c04878-f4ae-41fb-9533-c0979bf4b3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d52867-e933-4b50-8d38-b7f23eaa0a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Flatten, Reshape #\n",
    "from tensorflow.keras import Model, Sequential\n",
    "\n",
    "encoding_dim = 36 \n",
    "\n",
    "class Autoencoder(Model):\n",
    "    def __init__(self, encoding_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoding_dim = encoding_dim   \n",
    "        self.encoder = Sequential([\n",
    "#             InputLayer(input_shape=(28,28)),\n",
    "            Flatten(),\n",
    "            Dense(encoding_dim, activation='relu'),\n",
    "        ])\n",
    "        self.decoder = Sequential([\n",
    "            Dense(784, activation='sigmoid'),\n",
    "            Reshape((28, 28))\n",
    "        ])\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "autoencoder = Autoencoder(encoding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae07b854-4bce-46bf-a491-597ced3a6b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "autoencoder.fit(X_train, X_train, epochs=20,\n",
    "                batch_size=256,\n",
    "                validation_data=(X_test, X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad18658-225b-4154-8d0a-3ea00a86531c",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c259b3-8ad7-4271-b8a2-ffbd0b52cb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa119702-b90d-488d-bea5-13063d029083",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs = autoencoder.encoder(X_test).numpy() \n",
    "print(encoded_imgs.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d04cc0-1ff9-4b42-84a8-6770feeb4681",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()  \n",
    "decoded_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4051e15-a739-48da-8527-17294f2c0d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(encoded_imgs[0].reshape(6,6), cmap=plt.cm.gray_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bd720a-b552-4ef8-87d0-8c85863c3445",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(decoded_imgs[0], cmap=plt.cm.gray_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f040da0-22bd-4a99-9c91-9c7743801774",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 8\n",
    "plt.figure(figsize=(14-2, 5.8+2.7)) \n",
    "for i in range(n):\n",
    "    ax = plt.subplot(3, n, i + 1)\n",
    "    plt.title(\"original\")\n",
    "    plt.imshow(X_test[i], cmap=plt.cm.gray_r)\n",
    "    plt.xticks([]); plt.yticks([])\n",
    "\n",
    "    bx = plt.subplot(3, n, n+i+1)\n",
    "    plt.title(\"Encoded\")\n",
    "    plt.imshow(encoded_imgs[i].reshape(6,6), cmap=plt.cm.gray_r)\n",
    "\n",
    "    plt.xticks([]); plt.yticks([])\n",
    "\n",
    "    cx = plt.subplot(3, n, 2*n + i+ 1)\n",
    "    plt.title(\"Reconstructed\")\n",
    "    plt.imshow(decoded_imgs[i], cmap=plt.cm.gray_r)\n",
    "    plt.xticks([]); plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa37d82-92a8-428f-a880-77834e420c5c",
   "metadata": {},
   "source": [
    "# ws02 Denoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963831ef-7467-4b9a-a088-fe902e2c1f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, _), (X_test, _) = fashion_mnist.load_data()\n",
    "\n",
    "print(X_train.shape)\n",
    "\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "X_train = np.expand_dims(X_train, -1) # \n",
    "X_test = np.expand_dims(X_test, -1)\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e7a7d6-8e95-4919-bcd2-7a67b77b4860",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_factor = 0.2\n",
    "X_train_noisy = X_train + noise_factor * np.random.normal(loc=0.0, \n",
    "                                                          scale=1.0, size=X_train.shape) \n",
    "X_test_noisy = X_test + noise_factor * np.random.normal(loc=0.0, \n",
    "                                                        scale=1.0, size=X_test.shape) \n",
    "\n",
    "X_train_noisy = np.clip(X_train_noisy, 0., 1.)\n",
    "X_test_noisy = np.clip(X_test_noisy, 0., 1.)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e373df9-ff0d-4f13-962f-37b81b627cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = X_train_noisy[1]\n",
    "plt.imshow(img, cmap=plt.cm.gray_r) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f16cb5-13f9-43f5-8ecf-20ce4bc5fcaf",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6e2b4-6a2a-48f1-bac0-3f865bf90510",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.layers import InputLayer,Conv2D, Conv2DTranspose \n",
    "\n",
    "class Denoise(Model):\n",
    "    def __init__(self):\n",
    "        super(Denoise, self).__init__()\n",
    "        self.encoder = Sequential([\n",
    "\n",
    "            Conv2D(16, (3, 3), activation='relu', padding='same', strides=2),\n",
    "            Conv2D(8, (3, 3), activation='relu', padding='same', strides=2)])\n",
    "\n",
    "        self.decoder = Sequential([\n",
    "            Conv2DTranspose(8, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
    "            Conv2DTranspose(16, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
    "            Conv2D(1, kernel_size=(3, 3), activation='sigmoid', padding='same')])\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "autoencoder = Denoise()\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56914294-ba3b-4d76-9734-360349c53a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(X_train_noisy, X_train, epochs=10,\n",
    "                batch_size=128,\n",
    "                validation_data=(X_test, X_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110b8ddb-3828-4390-aa7f-437114409450",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17053b8-d007-4510-8a77-52fdce6919d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a46fc3-63d7-4dc5-8033-6af6b5cf222a",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs = autoencoder.encoder(X_test_noisy).numpy() \n",
    "print(encoded_imgs.shape)\n",
    "\n",
    "decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()\n",
    "decoded_imgs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ddf45f-67de-4d51-9b62-a9904ef6a72b",
   "metadata": {},
   "source": [
    "### Visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629cfabc-3e86-4424-8e5e-ba58442dabaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 8\n",
    "plt.figure(figsize=(12, 4))\n",
    "for i in range(n):\n",
    "\n",
    "    # display original + noise\n",
    "    ax = plt.subplot(2, n, i+1)\n",
    "    plt.title(\"Original+noise\")\n",
    "    plt.imshow(np.squeeze(X_test_noisy[i]), cmap=plt.cm.gray_r)\n",
    "    plt.imshow(X_test_noisy[i], cmap=plt.cm.gray_r)\n",
    "    plt.xticks([]); plt.yticks([])\n",
    "\n",
    "    # display reconstruction\n",
    "    bx = plt.subplot(2, n, i + n + 1)\n",
    "    plt.title(\"Reconstructed\")\n",
    "    plt.imshow(np.squeeze(decoded_imgs[i]), cmap=plt.cm.gray_r)\n",
    "    plt.xticks([]); plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d07163c-1201-462d-84e8-ce56ba60b8f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

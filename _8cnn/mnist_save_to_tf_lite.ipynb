{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-25 16:21:55.526884: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1600]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-10-25 16:21:55.531694: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-10-25 16:21:55.604461: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1600]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-10-25 16:21:55.614940: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,128]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/qm/p5vffjb56gvb80sz8bwjxy780000gn/T/tmptv8s06vw/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/qm/p5vffjb56gvb80sz8bwjxy780000gn/T/tmptv8s06vw/assets\n",
      "2023-10-25 16:21:56.235439: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2023-10-25 16:21:56.235452: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2023-10-25 16:21:56.235945: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /var/folders/qm/p5vffjb56gvb80sz8bwjxy780000gn/T/tmptv8s06vw\n",
      "2023-10-25 16:21:56.237124: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-10-25 16:21:56.237138: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /var/folders/qm/p5vffjb56gvb80sz8bwjxy780000gn/T/tmptv8s06vw\n",
      "2023-10-25 16:21:56.241229: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2023-10-25 16:21:56.302883: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /var/folders/qm/p5vffjb56gvb80sz8bwjxy780000gn/T/tmptv8s06vw\n",
      "2023-10-25 16:21:56.312501: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 76555 microseconds.\n"
     ]
    }
   ],
   "source": [
    "# save to regular tflite\n",
    "model = load_model('mnist_model.h5')\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# save the model\n",
    "with open('mnist_model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)\n",
    "\n",
    "tflite_size = os.path.getsize(\"mnist_model.tflite\")\n",
    "h5_size = os.path.getsize('mnist_model.h5')\n",
    "# print(tflite_size, h5_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-25 16:21:58.700619: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1600]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-10-25 16:21:58.705544: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-10-25 16:21:58.773020: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1600]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-10-25 16:21:58.782676: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,128]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/qm/p5vffjb56gvb80sz8bwjxy780000gn/T/tmpfg8tcx1v/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/qm/p5vffjb56gvb80sz8bwjxy780000gn/T/tmpfg8tcx1v/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "903620 2748704 2748704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-25 16:21:59.194770: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2023-10-25 16:21:59.194783: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2023-10-25 16:21:59.194921: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /var/folders/qm/p5vffjb56gvb80sz8bwjxy780000gn/T/tmpfg8tcx1v\n",
      "2023-10-25 16:21:59.195998: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-10-25 16:21:59.196003: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /var/folders/qm/p5vffjb56gvb80sz8bwjxy780000gn/T/tmpfg8tcx1v\n",
      "2023-10-25 16:21:59.199722: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2023-10-25 16:21:59.236435: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /var/folders/qm/p5vffjb56gvb80sz8bwjxy780000gn/T/tmpfg8tcx1v\n",
      "2023-10-25 16:21:59.245612: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 50692 microseconds.\n"
     ]
    }
   ],
   "source": [
    "# save to optimized tflite\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# save the model\n",
    "with open('mnist_model_optimized.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)\n",
    "\n",
    "tflite_opt_size = os.path.getsize('mnist_model.h5')\n",
    "print(tflite_size, h5_size, tflite_opt_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function Interpreter.tensor.<locals>.<lambda> at 0x159ef22a0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Applying 1 TensorFlow Lite delegate(s) lazily.\n",
      "VERBOSE: Replacing 8 node(s) with delegate (TfLiteXNNPackDelegate) node, yielding 1 partitions for the whole graph.\n",
      "INFO: Successfully applied the default TensorFlow Lite delegate indexed at 0.\n",
      " *NOTE*: because a delegate has been applied, the precision of computations should be unchanged, but the exact output tensor values may have changed. If such output values are checked in your code, like in your tests etc., please consider increasing error tolerance for the check.\n"
     ]
    }
   ],
   "source": [
    "# call tflite model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.image import rgb_to_grayscale\n",
    "from PIL import Image, ImageOps\n",
    "import tensorflow as tf\n",
    "from time import time\n",
    "import numpy as np\n",
    "\n",
    "tflite_path = 'mnist_model.tflite'\n",
    "interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "input_tensor_index = input_details[0]['index']\n",
    "\n",
    "output_details = interpreter.get_output_details()\n",
    "# print(output_details)\n",
    "\n",
    "output = interpreter.tensor(interpreter.get_output_details()[0][\"index\"])\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "# call tflite model\n",
    "img = load_img('number/3.png', target_size=(28,28))\n",
    "\n",
    "img = ImageOps.invert(img)\n",
    "img = img_to_array(img)\n",
    "img = rgb_to_grayscale(img)\n",
    "img = img/255.0\n",
    "img = np.expand_dims(img, axis=0)\n",
    "\n",
    "interpreter.set_tensor(input_tensor_index, img)\n",
    "interpreter.invoke()\n",
    "\n",
    "digit = np.argmax(output()[0])\n",
    "print(digit)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
